{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.ensemble import ExtraTreesRegressor\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.feature_selection import mutual_info_regression\n",
    "#from sklearn.linear_model import LassoCV\n",
    "#from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import f_regression,SelectPercentile,SelectFpr\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "#import pandas as pd\n",
    "\n",
    "p = sns.color_palette()\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "#from sklearn.linear_model import ElasticNet\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "#from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import Lasso\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "#from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import mstats\n",
    "from keras import optimizers\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network(train_data, data, n=55413):\n",
    "    newdata = pd.concat([train_data.ix[:,2:-2],train_data.ix[:,-1]], axis=1)\n",
    "    for i in range(28):\n",
    "        mad = newdata.ix[:,i].mad()\n",
    "        dif = np.abs(newdata.ix[:,i] - np.median(newdata.ix[:,i]))\n",
    "        newdata = newdata[dif <= 4*mad]\n",
    "    data_filtered = train_data.ix[newdata.index]\n",
    "    \n",
    "    X = data_filtered.iloc[:,2:-2].values\n",
    "    y = data_filtered.iloc[:,-1].values\n",
    "    weight = data_filtered.iloc[:,-2].values\n",
    "\n",
    "    #Extract optimal train data set\n",
    "    X_train = X[-n:]\n",
    "    y_train = y[-n:]\n",
    "    weight_train = weight[-n:]\n",
    "    X_test = data.iloc[:,2:-2].values\n",
    "    y_test = data.iloc[:,-1].values\n",
    "    \n",
    "    weight_test = data.iloc[:,-2].values\n",
    "    #lasso again\n",
    "    X_scaler = StandardScaler(copy = True, with_mean = True, with_std = True)\n",
    "    X_train = X_scaler.fit_transform(X_train)\n",
    "    X_test = X_scaler.fit_transform(X_test)\n",
    "    clf = LassoCV()\n",
    "    sfm = SelectFromModel(clf)\n",
    "    sfm.fit(X_train, y_train)\n",
    "    X_train = sfm.transform(X_train)\n",
    "    X_test = sfm.transform(X_test)\n",
    "    def baseline_model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(5, input_dim=len(X_train[0]), kernel_initializer='uniform', activation=\"tanh\"))\n",
    "        model.add(Dense(1, kernel_initializer='uniform'))\n",
    "        # Compile model\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('mlp', KerasRegressor(build_fn=baseline_model,sample_weight = weight_train, epochs=150, batch_size=1500,\n",
    "                                             verbose=0)))#callbacks=[change_lr] )))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    pipeline.fit(X_train, y_train)#callbacks=callbacks_list)\n",
    "    return pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_model(train_data, data, feature_num, cv_splits):\n",
    "    # Scale data\n",
    "    test_data = data\n",
    "\n",
    "    train_x = train_data.drop(['y','weight','id'], axis = 1)\n",
    "    train_y = train_data['y']\n",
    "    train_sample_weight = train_data['weight']\n",
    "    \n",
    "    test_x = test_data.drop(['y','weight','id'], axis = 1)\n",
    "    test_y = test_data['y']\n",
    "    test_sample_weight = test_data['weight']\n",
    "\n",
    "    scaler = StandardScaler().fit(train_x)\n",
    "    scaled_train_x = scaler.transform(train_x)\n",
    "    scaled_test_x = scaler.transform(test_x)\n",
    "    \n",
    "    # Select feature\n",
    "    pca = PCA(n_components= feature_num).fit(scaled_train_x)\n",
    "    selected_train_x = pca.transform(scaled_train_x)\n",
    "    selected_test_x = pca.transform(scaled_test_x)\n",
    "    \n",
    "    # Model fit\n",
    "    tscv = TimeSeriesSplit(n_splits = cv_splits)\n",
    "    lasso_cv = LassoCV(cv = tscv)\n",
    "    lasso_cv.fit(selected_train_x, train_y)\n",
    "    \n",
    "    test_y_predicted = lasso_cv.predict(selected_test_x)\n",
    "    return test_y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_boost(params,X,X_holdout,y):\n",
    "    '''gradient boosting\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: parameters in the gradient boosting\n",
    "    X: data X\n",
    "    y: data y\n",
    "    k: split folds'''\n",
    "    \n",
    "    # scale data\n",
    "    X_scaler = StandardScaler(copy = True, with_mean = True, with_std = True)\n",
    "    X_train = X_scaler.fit_transform(X)\n",
    "    X_test = X_scaler.transform(X_holdout)\n",
    "    \n",
    "    # lasso feature selection\n",
    "    clf = LassoCV()\n",
    "    sfm = SelectFromModel(clf)\n",
    "    sfm.fit(X_train, y)\n",
    "    X_train_lasso = sfm.transform(X_train)\n",
    "    X_test_lasso = sfm.transform(X_test)\n",
    "    \n",
    "    # fit \n",
    "    est = GradientBoostingRegressor(**params)\n",
    "    est.fit(X_train_lasso, y)\n",
    "    y_predict = est.predict(X_test_lasso)\n",
    "    \n",
    "    return y_predict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_model(train_data, data):\n",
    "    y1 = regression_model(train_data, data, 18, 9)\n",
    "    \n",
    "    params = {'n_estimators':50, 'learning_rate':0.08, 'subsample':0.8,\n",
    "          'max_depth': 1, 'random_state': 0,'min_samples_split': 5}\n",
    "    \n",
    "    \n",
    "    X_holdout = data.drop(['y','timestamp','id'],1).values\n",
    "    X = train_data.drop(['y','timestamp','id'],1).values\n",
    "    y = train_data['y'].values\n",
    "    y2 = gradient_boost(params,X,X_holdout,y)\n",
    "    \n",
    "    y3 =  neural_network(train_data, data, )\n",
    "    \n",
    "    ratio_1 = 0.1\n",
    "    ratio_2 = 0.1\n",
    "    ratio_3 = 0.8\n",
    "    return ratio_1 * y1 + ratio_2 * y2 + ratio_3 * y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_model(my_model, data):\n",
    "    train_data = pd.read_pickle(\"C:/Users/JYJ/Downloads/train/ml_finalproj_train_vF.pkl\")\n",
    "    predicted_y = my_model(train_data, data)\n",
    "    return r2_score(data['y'], predicted_y, data['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"ml_finalproj_train_vF.pkl\")\n",
    "data = pd.read_pickle(\"ml_finalproj_holdout.pkl\")\n",
    "predicted_y = final_model(train_data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['y'] = predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -5.916806e-04\n",
       "1        6.790082e-04\n",
       "2       -2.194383e-04\n",
       "3        3.876608e-04\n",
       "4       -1.038230e-03\n",
       "5       -1.538144e-04\n",
       "6        4.912941e-04\n",
       "7       -3.226350e-04\n",
       "8       -7.921618e-04\n",
       "9        3.126851e-04\n",
       "10      -2.641546e-04\n",
       "11      -1.000166e-03\n",
       "12       1.665322e-04\n",
       "13       8.126695e-05\n",
       "14      -1.083846e-04\n",
       "15      -4.781138e-04\n",
       "16       1.384345e-04\n",
       "17      -1.077992e-03\n",
       "18      -2.908285e-04\n",
       "19      -5.807687e-04\n",
       "20       4.496707e-05\n",
       "21      -1.699827e-04\n",
       "22      -1.158355e-05\n",
       "23      -8.026500e-04\n",
       "24      -1.872352e-07\n",
       "25      -1.920384e-04\n",
       "26       7.530914e-05\n",
       "27       4.750644e-04\n",
       "28      -2.773804e-04\n",
       "29      -1.492017e-04\n",
       "             ...     \n",
       "34683   -9.000669e-04\n",
       "34684    2.160469e-04\n",
       "34685    2.745437e-04\n",
       "34686   -1.294714e-04\n",
       "34687   -2.798820e-04\n",
       "34688    2.924427e-04\n",
       "34689   -8.387194e-04\n",
       "34690    6.157406e-05\n",
       "34691    1.481896e-04\n",
       "34692   -3.007374e-04\n",
       "34693   -3.893453e-04\n",
       "34694    4.064684e-04\n",
       "34695    8.051976e-04\n",
       "34696   -8.111577e-04\n",
       "34697    6.698068e-05\n",
       "34698    4.586405e-04\n",
       "34699   -2.690892e-04\n",
       "34700   -5.419808e-05\n",
       "34701   -7.435142e-05\n",
       "34702    1.558683e-04\n",
       "34703   -2.317705e-04\n",
       "34704   -4.316805e-06\n",
       "34705   -4.496960e-04\n",
       "34706   -2.933089e-04\n",
       "34707   -7.611896e-04\n",
       "34708   -2.639587e-04\n",
       "34709    1.347581e-04\n",
       "34710    5.299561e-04\n",
       "34711   -4.200944e-04\n",
       "34712    1.447725e-04\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_pickle(\"ml_finalproj_holdout_filled.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
